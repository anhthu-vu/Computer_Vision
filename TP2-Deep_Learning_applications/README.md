In these practical sessions, we . To be more specific: 

- In `2-a: Transfer Learning` section, we implemented a transfer learning framework using the entire VGG16 network—except for its last two layers—with pretrained weights on ImageNet. We combined this with several downstream architectures, including a linear SVC and a fully connected layer (with and without propagating the gradients to the rest of the network), to perform a classification task on the 15 Scene dataset, then conducted an analysis of the test results to evaluate and compare the performance of the different configurations.
- In `2-b: Visualization` section, we applied three techniques—Saliency Map, Adversarial Example, and Class Visualization—to study the behavior of convolutional neural networks, specifically how the network processes the image to produce predictions. 
- In `2-c: Domain Adaptation` section, we implemented the DANN model proposed by Y. Ganin and V. Lempitsky in [this paper](https://arxiv.org/abs/1409.7495), one of many effective domain adaptation techniques. The model was trained on the labeled MNIST and unlabeled MNIST-M datasets.
- In `2-de: Generative Adversarial Networks` section, we implemented two examples of GANs: Deep Convolutional GAN (DCGAN) and conditional DCGAN (cDCGAN), proposed by A. Radford, L. Metz, and S. Chintala in [this paper](https://arxiv.org/abs/1511.06434), and trained them on the MNIST dataset. We then performed some experiments with various hyperparameters values to analyze their effects on models' performance.
